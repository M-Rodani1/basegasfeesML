{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Gas Fee Prediction - Model Training\n",
    "## LSTM + Prophet Model Training with GPU Acceleration\n",
    "\n",
    "This notebook trains time-series models for gas fee prediction using 6 months of historical data.\n",
    "\n",
    "**Hardware Recommendation**: Use GPU runtime (T4 or better)\n",
    "- Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q tensorflow prophet scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Database\n",
    "\n",
    "**IMPORTANT**: Upload your `gas_data.db` file from:\n",
    "`/Users/rodan/Documents/gasFeesPrediction-main/backend/gas_data.db`\n",
    "\n",
    "Click the folder icon on the left ‚Üí Upload button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Check if database exists\n",
    "db_file = 'gas_data.db'\n",
    "\n",
    "if not os.path.exists(db_file):\n",
    "    print(\"‚ö†Ô∏è  Database not found!\")\n",
    "    print(\"\\nPlease upload 'gas_data.db' from your local machine:\")\n",
    "    print(\"/Users/rodan/Documents/gasFeesPrediction-main/backend/gas_data.db\")\n",
    "    print(\"\\nUploading now...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Check if uploaded file needs renaming\n",
    "    if 'gas_data.db' not in uploaded and len(uploaded) > 0:\n",
    "        uploaded_name = list(uploaded.keys())[0]\n",
    "        if uploaded_name.endswith('.db'):\n",
    "            os.rename(uploaded_name, 'gas_data.db')\n",
    "            print(f\"‚úì Renamed {uploaded_name} to gas_data.db\")\n",
    "else:\n",
    "    print(\"‚úì Database file found\")\n",
    "\n",
    "# Verify database\n",
    "try:\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Check tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(f\"\\n‚úì Database tables: {[t[0] for t in tables]}\")\n",
    "    \n",
    "    # Check record count\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM gas_prices\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"‚úì Total gas price records: {count:,}\")\n",
    "    \n",
    "    cursor.execute(\"SELECT MIN(timestamp), MAX(timestamp) FROM gas_prices\")\n",
    "    date_range = cursor.fetchone()\n",
    "    print(f\"‚úì Date range: {date_range[0]} to {date_range[1]}\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\n‚úì Database verified successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error verifying database: {e}\")\n",
    "    print(\"Please make sure you uploaded the correct gas_data.db file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Connect to database\nconn = sqlite3.connect('gas_data.db')\n\n# Load historical gas prices\nquery = \"\"\"\nSELECT timestamp, current_gas as gas_price, block_number\nFROM gas_prices\nORDER BY timestamp ASC\n\"\"\"\n\ndf = pd.read_sql_query(query, conn)\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\nconn.close()\n\nprint(f\"‚úì Loaded {len(df):,} records\")\nprint(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\nprint(f\"Duration: {(df['timestamp'].max() - df['timestamp'].min()).days} days\")\nprint(f\"\\nGas price stats:\")\nprint(df['gas_price'].describe())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['day_of_month'] = df['timestamp'].dt.day\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    for window in [12, 24, 48, 168]:  # 1h, 2h, 4h, 1week (5-min intervals)\n",
    "        df[f'rolling_mean_{window}'] = df['gas_price'].rolling(window=window, min_periods=1).mean()\n",
    "        df[f'rolling_std_{window}'] = df['gas_price'].rolling(window=window, min_periods=1).std().fillna(0)\n",
    "        df[f'rolling_min_{window}'] = df['gas_price'].rolling(window=window, min_periods=1).min()\n",
    "        df[f'rolling_max_{window}'] = df['gas_price'].rolling(window=window, min_periods=1).max()\n",
    "    \n",
    "    # Lag features\n",
    "    for lag in [1, 2, 3, 6, 12, 24]:\n",
    "        df[f'lag_{lag}'] = df['gas_price'].shift(lag).fillna(df['gas_price'].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_features(df)\n",
    "print(f\"‚úì Created {len(df.columns)} features\")\n",
    "print(f\"Features: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 80% for training, 20% for testing\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df[:split_idx].copy()\n",
    "test_df = df[split_idx:].copy()\n",
    "\n",
    "print(f\"‚úì Training set: {len(train_df):,} records ({train_df['timestamp'].min()} to {train_df['timestamp'].max()})\")\n",
    "print(f\"‚úì Test set: {len(test_df):,} records ({test_df['timestamp'].min()} to {test_df['timestamp'].max()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LSTM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(df, feature_cols, lookback=24, horizon=12):\n",
    "    \"\"\"Prepare sequences for LSTM training\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(df[feature_cols])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(scaled_features) - horizon):\n",
    "        X.append(scaled_features[i-lookback:i])\n",
    "        y.append(df['gas_price'].iloc[i + horizon])\n",
    "    \n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"Build Bidirectional LSTM model\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "            input_shape=input_shape\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(64, return_sequences=True)\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(32)\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úì LSTM functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns for LSTM\n",
    "feature_cols = [col for col in df.columns if col not in ['timestamp', 'block_number']]\n",
    "\n",
    "# Training parameters\n",
    "horizons = {\n",
    "    '1h': 12,   # 12 * 5min = 1 hour\n",
    "    '4h': 48,   # 48 * 5min = 4 hours\n",
    "    '24h': 288  # 288 * 5min = 24 hours\n",
    "}\n",
    "\n",
    "lstm_models = {}\n",
    "lstm_scalers = {}\n",
    "lstm_results = {}\n",
    "\n",
    "for horizon_name, horizon_steps in horizons.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training LSTM for {horizon_name} horizon ({horizon_steps} steps)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, y_train, scaler = prepare_lstm_data(\n",
    "        train_df, feature_cols, lookback=24, horizon=horizon_steps\n",
    "    )\n",
    "    X_test, y_test, _ = prepare_lstm_data(\n",
    "        test_df, feature_cols, lookback=24, horizon=horizon_steps\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train):,}\")\n",
    "    print(f\"Test samples: {len(X_test):,}\")\n",
    "    print(f\"Input shape: {X_train.shape}\")\n",
    "    \n",
    "    # Build and train model\n",
    "    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining LSTM model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test, verbose=0).flatten()\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Directional accuracy\n",
    "    actual_direction = np.diff(y_test) > 0\n",
    "    pred_direction = np.diff(y_pred) > 0\n",
    "    directional_accuracy = np.mean(actual_direction == pred_direction)\n",
    "    \n",
    "    lstm_results[horizon_name] = {\n",
    "        'mae': float(mae),\n",
    "        'rmse': float(rmse),\n",
    "        'r2_score': float(r2),\n",
    "        'directional_accuracy': float(directional_accuracy)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úì LSTM {horizon_name} Results:\")\n",
    "    print(f\"  MAE: {mae:.6f}\")\n",
    "    print(f\"  RMSE: {rmse:.6f}\")\n",
    "    print(f\"  R¬≤ Score: {r2:.4f} ({r2*100:.1f}%)\")\n",
    "    print(f\"  Directional Accuracy: {directional_accuracy:.4f} ({directional_accuracy*100:.1f}%)\")\n",
    "    \n",
    "    # Store model and scaler\n",
    "    lstm_models[horizon_name] = model\n",
    "    lstm_scalers[horizon_name] = scaler\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úì All LSTM models trained successfully\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prophet Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_models = {}\n",
    "prophet_results = {}\n",
    "\n",
    "for horizon_name, horizon_steps in horizons.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Prophet for {horizon_name} horizon\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Prepare data for Prophet\n",
    "    prophet_df = train_df[['timestamp', 'gas_price']].copy()\n",
    "    prophet_df.columns = ['ds', 'y']\n",
    "    \n",
    "    # Initialize and train Prophet\n",
    "    model = Prophet(\n",
    "        changepoint_prior_scale=0.05,\n",
    "        seasonality_prior_scale=10.0,\n",
    "        daily_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=False\n",
    "    )\n",
    "    \n",
    "    print(\"Training Prophet model...\")\n",
    "    model.fit(prophet_df)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    test_prophet = test_df[['timestamp', 'gas_price']].copy()\n",
    "    test_prophet.columns = ['ds', 'y']\n",
    "    \n",
    "    forecast = model.predict(test_prophet[['ds']])\n",
    "    y_pred = forecast['yhat'].values\n",
    "    y_test = test_prophet['y'].values\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Directional accuracy\n",
    "    actual_direction = np.diff(y_test) > 0\n",
    "    pred_direction = np.diff(y_pred) > 0\n",
    "    directional_accuracy = np.mean(actual_direction == pred_direction)\n",
    "    \n",
    "    prophet_results[horizon_name] = {\n",
    "        'mae': float(mae),\n",
    "        'rmse': float(rmse),\n",
    "        'r2_score': float(r2),\n",
    "        'directional_accuracy': float(directional_accuracy)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úì Prophet {horizon_name} Results:\")\n",
    "    print(f\"  MAE: {mae:.6f}\")\n",
    "    print(f\"  RMSE: {rmse:.6f}\")\n",
    "    print(f\"  R¬≤ Score: {r2:.4f} ({r2*100:.1f}%)\")\n",
    "    print(f\"  Directional Accuracy: {directional_accuracy:.4f} ({directional_accuracy*100:.1f}%)\")\n",
    "    \n",
    "    prophet_models[horizon_name] = model\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úì All Prophet models trained successfully\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for horizon_name in horizons.keys():\n",
    "    print(f\"\\n{horizon_name.upper()} HORIZON:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    lstm_res = lstm_results[horizon_name]\n",
    "    prophet_res = prophet_results[horizon_name]\n",
    "    \n",
    "    print(f\"\\nLSTM:\")\n",
    "    print(f\"  MAE:                  {lstm_res['mae']:.6f}\")\n",
    "    print(f\"  RMSE:                 {lstm_res['rmse']:.6f}\")\n",
    "    print(f\"  R¬≤ Score:             {lstm_res['r2_score']:.4f} ({lstm_res['r2_score']*100:.1f}%)\")\n",
    "    print(f\"  Directional Accuracy: {lstm_res['directional_accuracy']:.4f} ({lstm_res['directional_accuracy']*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nProphet:\")\n",
    "    print(f\"  MAE:                  {prophet_res['mae']:.6f}\")\n",
    "    print(f\"  RMSE:                 {prophet_res['rmse']:.6f}\")\n",
    "    print(f\"  R¬≤ Score:             {prophet_res['r2_score']:.4f} ({prophet_res['r2_score']*100:.1f}%)\")\n",
    "    print(f\"  Directional Accuracy: {prophet_res['directional_accuracy']:.4f} ({prophet_res['directional_accuracy']*100:.1f}%)\")\n",
    "    \n",
    "    # Determine winner\n",
    "    lstm_score = (lstm_res['r2_score'] + lstm_res['directional_accuracy']) / 2\n",
    "    prophet_score = (prophet_res['r2_score'] + prophet_res['directional_accuracy']) / 2\n",
    "    \n",
    "    winner = \"LSTM\" if lstm_score > prophet_score else \"Prophet\"\n",
    "    print(f\"\\n  üèÜ Best Model: {winner}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save LSTM models\n",
    "for horizon_name, model in lstm_models.items():\n",
    "    model_path = f'models/lstm_{horizon_name}.keras'\n",
    "    model.save(model_path)\n",
    "    print(f\"‚úì Saved LSTM {horizon_name} to {model_path}\")\n",
    "    \n",
    "    # Save scaler\n",
    "    scaler_path = f'models/lstm_{horizon_name}_scaler.pkl'\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(lstm_scalers[horizon_name], f)\n",
    "    print(f\"‚úì Saved scaler to {scaler_path}\")\n",
    "\n",
    "# Save Prophet models\n",
    "for horizon_name, model in prophet_models.items():\n",
    "    model_path = f'models/prophet_{horizon_name}.pkl'\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"‚úì Saved Prophet {horizon_name} to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'lstm': lstm_results,\n",
    "    'prophet': prophet_results,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'training_records': len(train_df),\n",
    "    'test_records': len(test_df)\n",
    "}\n",
    "\n",
    "with open('models/training_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\n‚úì Saved training results to models/training_results.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì All models saved successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download Models\n",
    "\n",
    "Download all trained models and results to your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip all models\n",
    "!zip -r trained_models.zip models/\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('trained_models.zip')\n",
    "\n",
    "print(\"\\n‚úì Models packaged and downloaded!\")\n",
    "print(\"\\nExtract the zip file and copy the models/ directory to:\")\n",
    "print(\"/Users/rodan/Documents/gasFeesPrediction-main/backend/models/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}